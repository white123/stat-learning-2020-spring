{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資管四 唐瑋廷 B05705043 HW3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取&分析data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30162.000000</td>\n",
       "      <td>3.016200e+04</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.437902</td>\n",
       "      <td>1.897938e+05</td>\n",
       "      <td>10.121312</td>\n",
       "      <td>1092.007858</td>\n",
       "      <td>88.372489</td>\n",
       "      <td>40.931238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.134665</td>\n",
       "      <td>1.056530e+05</td>\n",
       "      <td>2.549995</td>\n",
       "      <td>7406.346497</td>\n",
       "      <td>404.298370</td>\n",
       "      <td>11.979984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.176272e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.784250e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.376285e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  30162.000000  3.016200e+04   30162.000000  30162.000000  30162.000000   \n",
       "mean      38.437902  1.897938e+05      10.121312   1092.007858     88.372489   \n",
       "std       13.134665  1.056530e+05       2.549995   7406.346497    404.298370   \n",
       "min       17.000000  1.376900e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.176272e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.784250e+05      10.000000      0.000000      0.000000   \n",
       "75%       47.000000  2.376285e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    30162.000000  \n",
       "mean        40.931238  \n",
       "std         11.979984  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_list = ['workclass', 'occupation', 'native-country']\n",
    "train_data = pd.read_csv('adult.data', skipinitialspace=True)\n",
    "for c in remove_list:\n",
    "    train_data = train_data[~train_data[c].isin(['?'])]\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把 binary variable 轉成 one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 104)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = pd.DataFrame(pd.get_dummies(train_data.drop('label', axis=1)))\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢查 one-hot feature，剔除樣本數不到10的 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 102)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in train_x.columns[6:]: # first 6 columns are continuous varibles\n",
    "    if sum(train_x[c]) < 10:\n",
    "        train_x = train_x.drop(c, axis=1)\n",
    "features = train_x.columns # use of test data\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {'<=50K': 0, '>50K': 1, '<=50K.': 0, '>50K.': 1}\n",
    "train_y = train_data['label'].map(label_dict)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取 test data 並只保留 training data 有的 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15060.000000</td>\n",
       "      <td>1.506000e+04</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.768327</td>\n",
       "      <td>1.896164e+05</td>\n",
       "      <td>10.112749</td>\n",
       "      <td>1120.301594</td>\n",
       "      <td>89.041899</td>\n",
       "      <td>40.951594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.380676</td>\n",
       "      <td>1.056150e+05</td>\n",
       "      <td>2.558727</td>\n",
       "      <td>7703.181842</td>\n",
       "      <td>406.283245</td>\n",
       "      <td>12.062831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.166550e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.779550e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.385888e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3770.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  15060.000000  1.506000e+04   15060.000000  15060.000000  15060.000000   \n",
       "mean      38.768327  1.896164e+05      10.112749   1120.301594     89.041899   \n",
       "std       13.380676  1.056150e+05       2.558727   7703.181842    406.283245   \n",
       "min       17.000000  1.349200e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.166550e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.779550e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.385888e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   3770.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    15060.000000  \n",
       "mean        40.951594  \n",
       "std         12.062831  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('adult.test', skipinitialspace=True)\n",
    "for c in remove_list:\n",
    "    test_data = test_data[~test_data[c].isin(['?'])]\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 103)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = pd.DataFrame(pd.get_dummies(test_data.drop('label', axis=1)))\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 102)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in test_x.columns[6:]: # first 6 columns are continuous varibles\n",
    "    if c not in features:\n",
    "        test_x = test_x.drop(c, axis=1)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test_data['label'].map(label_dict)\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "train_y = train_y.to_numpy()\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E(\\omega) = \\frac{1}{2}\\omega^T\\Lambda\\omega - \\sum_{i=1}^n\\{t_nln(y_n) + (1-t_n)ln(1-y_n)\\},\\,y_n = \\frac{1}{1+exp(-\\omega^Tx_n)}$$\\\n",
    "$$\\nabla E(\\omega) = \\frac{1}{2}(\\Lambda^T + \\Lambda)\\omega + \\sum_{i=1}^n (y_i - t_i)\\phi_i = \\Lambda\\omega + \\phi^T (y - t)$$\\\n",
    "$$H = \\nabla\\nabla E(\\omega) = \\Lambda + \\sum_{i=1}^n y_i(1-y_i)\\phi_i \\phi_i^T = \\Lambda + \\phi R \\phi^T$$\n",
    "<center>where R is a NxN diagonal matrix with elements: $R_{nn} = y_n(1-y_n)$<\\center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 1000, tol = 1e-5, add_intercept = True):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "       \n",
    "    def fit(self, x, t):\n",
    "        # add intercept\n",
    "        if self.add_intercept:\n",
    "            x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
    "    \n",
    "        # init w\n",
    "        b = self.reg_vec.trace() / self.reg_vec.shape[0]\n",
    "        self.w = np.linalg.inv(x.T.dot(x) + b * np.identity(x.shape[1])).dot(x.T).dot(t)\n",
    "        \n",
    "        last_err = float(\"-inf\")\n",
    "        for _ in range(self.max_iter):\n",
    "            # Newton-Raphson optimization method\n",
    "            y = expit(self.w.T.dot(x.T))\n",
    "            cur_err = self.err(y, t)\n",
    "#             print(cur_err, (self.w**2).sum())\n",
    "            if (cur_err - last_err) < self.tol:\n",
    "                break\n",
    "            last_err = cur_err\n",
    "            \n",
    "            gradient = self.reg_vec.dot(self.w) + x.T.dot(y-t)\n",
    "            r = np.diagflat(y*(1-y))\n",
    "            h = self.reg_vec + x.T.dot(r).dot(x)\n",
    "            \n",
    "            self.w = self.w - np.linalg.inv(h).dot(gradient)\n",
    "            \n",
    "            pred = np.where(y > 0.5, 1, 0)\n",
    "            print(f'acc: {sum(np.equal(pred, t)) / t.shape[0]}')\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.add_intercept:\n",
    "            x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
    "        p = expit(self.w.T.dot(x.T))\n",
    "        return np.where(p > 0.5, 1, 0)\n",
    "    \n",
    "    def err(self, y, t):\n",
    "        y = np.clip(y, 1e-12, 1.-1e-12)\n",
    "        return np.sum(self.w.T.dot(self.reg_vec).dot(self.w))/2 - np.sum(t*np.log(y) + (1-t)*np.log(1-y)) / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 1: lambda = 1 for all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic1 = mylogistic_l2(np.identity(train_x.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.45040116703136396\n",
      "acc: 0.8377428552483257\n",
      "acc: 0.8466282076785359\n",
      "acc: 0.8493137059876666\n",
      "acc: 0.8496784032889065\n",
      "acc: 0.8495789403885684\n",
      "acc: 0.8495789403885684\n",
      "acc: 0.8495789403885684\n"
     ]
    }
   ],
   "source": [
    "logic1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict & show test accuracy and learned w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8480743691899071\n",
      "w: [ 2.48591297e-02  7.26281835e-07  1.85806163e-01  3.16590245e-04\n",
      "  6.38679434e-04  2.90215841e-02  1.89694410e-01 -4.97719502e-01\n",
      " -3.10975203e-01 -1.29181492e-01 -7.94111558e-01 -6.18745004e-01\n",
      " -1.17270706e+00 -4.52249248e-01 -5.44907404e-01 -3.82721833e-01\n",
      " -9.99810311e-02 -2.62922226e-01 -6.29791390e-01 -4.96565840e-01\n",
      " -3.08326937e-01 -1.27584811e-01  1.28534378e-01  5.87953356e-01\n",
      " -2.50481307e-01  2.99991415e-01 -1.37579993e+00  6.82097030e-01\n",
      " -1.00989638e-01 -1.00975740e+00  1.19612260e+00  8.38966951e-01\n",
      " -9.56673074e-01 -1.50523219e+00 -1.08232392e+00 -8.14848370e-01\n",
      " -8.78492153e-02 -2.46913578e-02  7.15174653e-01 -1.06504054e+00\n",
      " -7.73348089e-01 -3.53722827e-01 -9.03671285e-01 -1.69395624e+00\n",
      "  4.29670534e-01  4.99488476e-01  2.05962312e-01  5.68478621e-01\n",
      " -1.78947443e-01 -5.76254831e-01 -3.75781230e-01 -1.12608336e+00\n",
      " -1.50192093e+00 -5.01524893e-01  7.47819833e-01 -1.02439618e+00\n",
      " -2.92668734e-01 -6.35195702e-01 -8.96890178e-01 -4.84594619e-01\n",
      " -2.09367501e+00 -1.24007040e+00  9.03420736e-01  4.04668560e-01\n",
      " -5.46920551e-01 -1.31374667e+00  4.27865169e-01 -9.47705967e-01\n",
      " -1.07395558e-01 -4.09492098e-01  3.77034140e-01  5.45751678e-01\n",
      "  5.23589384e-01 -6.70323916e-01 -1.09516216e-01  4.53277948e-02\n",
      " -1.63971889e-01 -4.71983492e-02 -4.02281404e-03 -3.44708812e-01\n",
      "  1.03362979e-01  4.50497096e-01  8.22875669e-01  9.41389496e-02\n",
      "  2.92357805e-01 -3.50891475e-01 -4.39859205e-01 -4.07586321e-01\n",
      " -6.90804284e-01 -4.47783816e-01  3.91129903e-01  8.03243758e-02\n",
      "  7.97357703e-02 -1.81402777e-01 -9.03628229e-02 -9.81576059e-01\n",
      " -7.79910252e-02 -3.31100773e-01 -1.88816101e-01  2.89337136e-01\n",
      " -8.34197419e-01  5.39068128e-01 -3.33374541e+00]\n"
     ]
    }
   ],
   "source": [
    "predict = logic1.predict(test_x)\n",
    "acc = sum(np.equal(predict, test_y)) / test_y.shape[0]\n",
    "print(f'test accuracy: {acc}')\n",
    "print(f'w: {logic1.w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 2: lambda = 1 for all but the intercept, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vec = np.identity(train_x.shape[1]+1)\n",
    "reg_vec[-1][-1] = 0\n",
    "logic2 = mylogistic_l2(reg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.45040116703136396\n",
      "acc: 0.8376765466481002\n",
      "acc: 0.8466613619786486\n",
      "acc: 0.8493137059876666\n",
      "acc: 0.8495789403885684\n",
      "acc: 0.8496120946886812\n",
      "acc: 0.8496120946886812\n",
      "acc: 0.8496120946886812\n"
     ]
    }
   ],
   "source": [
    "logic2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict & show test accuracy and learned w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.847808764940239\n",
      "w: [ 2.54336822e-02  7.50706804e-07  2.95324923e-01  3.17024478e-04\n",
      "  6.39652126e-04  2.94914512e-02  7.05717318e-01  1.78026500e-02\n",
      "  2.09126595e-01  3.82731145e-01 -2.79821711e-01 -1.04552949e-01\n",
      " -9.31003048e-01  9.08118762e-02 -1.06210390e-01 -5.68864880e-02\n",
      "  7.06129017e-01  5.36014978e-01  1.16361327e-01  1.37527872e-01\n",
      " -4.01951496e-01 -1.13370201e-01 -7.43801938e-02  6.79669927e-02\n",
      " -1.95742294e-02 -1.15929727e-02 -1.15969699e+00  2.67049827e-01\n",
      "  2.18010721e-02 -5.26538178e-01  1.61452758e+00  1.36751001e+00\n",
      " -4.92456781e-01 -1.01532722e+00 -6.05766415e-01 -3.41949002e-01\n",
      "  1.64109182e-01  2.28422252e-01  9.64856017e-01 -8.17967488e-01\n",
      " -5.20782272e-01 -9.91243550e-02 -6.49283758e-01 -1.55300394e+00\n",
      "  6.78427764e-01  7.51030497e-01  4.55411798e-01  8.18714335e-01\n",
      "  7.31938653e-02 -4.21151206e-02  1.99456866e-01 -5.83542666e-01\n",
      " -9.36996740e-01  7.53014758e-02  1.28789619e+00 -3.72048376e-01\n",
      "  3.94360616e-01  4.30693947e-02 -2.61235808e-01  1.95854174e-01\n",
      " -4.27150728e-01  4.27150728e-01  1.00965472e+00  5.02337197e-01\n",
      " -4.58396918e-01 -1.24053337e+00  5.27833699e-01 -8.67620758e-01\n",
      " -2.75702550e-02 -3.15345728e-01  4.72832596e-01  6.28755384e-01\n",
      "  6.23911101e-01 -5.88433188e-01 -2.96923355e-02  1.24844059e-01\n",
      " -1.43574430e-01  2.48070507e-02  6.14826819e-02 -2.48769643e-01\n",
      "  1.94794455e-01  5.25952046e-01  9.31972681e-01  1.87606692e-01\n",
      "  3.79606530e-01 -2.87259337e-01 -3.10421302e-01 -3.32413817e-01\n",
      " -6.50777756e-01 -3.81261235e-01  4.89030076e-01  1.76281854e-01\n",
      "  1.74545517e-01 -7.36414561e-02 -3.10934763e-02 -8.98503737e-01\n",
      "  6.72286129e-03 -2.72168679e-01 -1.23870297e-01  3.96789072e-01\n",
      " -7.54273373e-01  6.10526925e-01 -8.88722780e+00]\n"
     ]
    }
   ],
   "source": [
    "predict = logic2.predict(test_x)\n",
    "acc = sum(np.equal(predict, test_y)) / test_y.shape[0]\n",
    "print(f'test accuracy: {acc}')\n",
    "print(f'w: {logic2.w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vec = np.diagflat(np.array([1]*6 + [0.5]*(train_x.shape[1]-6) + [0]))\n",
    "logic3 = mylogistic_l2(reg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.4504343213314767\n",
      "acc: 0.8378091638485512\n",
      "acc: 0.8468271334792122\n",
      "acc: 0.8492805516875539\n",
      "acc: 0.8496784032889065\n",
      "acc: 0.8496784032889065\n",
      "acc: 0.8496452489887939\n",
      "acc: 0.8496452489887939\n"
     ]
    }
   ],
   "source": [
    "logic3.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict & show test accuracy and learned w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.847675962815405\n",
      "w: [ 2.54757306e-02  7.51944312e-07  3.19092342e-01  3.17319913e-04\n",
      "  6.40115460e-04  2.95135991e-02  7.66990116e-01  7.62915465e-02\n",
      "  2.68338059e-01  4.43128005e-01 -2.20821080e-01 -4.63422172e-02\n",
      " -1.28758443e+00  2.18992475e-01 -2.26138731e-03  2.18816236e-02\n",
      "  9.74981437e-01  7.54034100e-01  2.92224730e-01  2.93070078e-01\n",
      " -4.19612080e-01 -1.04346489e-01 -1.12963414e-01 -3.78240642e-02\n",
      "  3.76517836e-02 -7.30516163e-02 -2.08394383e+00  1.86338344e-01\n",
      "  5.48283061e-02 -5.72016463e-01  1.82571096e+00  1.39641689e+00\n",
      " -5.47067026e-01 -1.05936562e+00 -6.55642151e-01 -3.88036591e-01\n",
      "  2.36234456e-01  3.00253533e-01  1.03825745e+00 -7.52669809e-01\n",
      " -4.53424415e-01 -2.69071693e-02 -5.82347571e-01 -2.00233647e+00\n",
      "  7.51037233e-01  8.27361969e-01  5.28330008e-01  8.95057963e-01\n",
      "  1.45241841e-01 -8.34438407e-02  2.32699144e-01 -5.92702337e-01\n",
      " -9.22764551e-01  1.11240624e-01  1.25497096e+00 -3.83664192e-01\n",
      "  4.13058381e-01  4.13741738e-02 -2.63868161e-01  1.93099799e-01\n",
      " -4.29102319e-01  4.29102319e-01  1.18913496e+00  5.50823608e-01\n",
      " -4.76703525e-01 -1.45906500e+00  5.82266265e-01 -1.06198153e+00\n",
      " -9.41603138e-03 -3.18451360e-01  5.24213674e-01  7.29262555e-01\n",
      "  6.74417681e-01 -6.38233985e-01 -9.70381962e-03  1.74242999e-01\n",
      " -2.36216831e-01  3.80746796e-02  1.00364760e-01 -2.47188688e-01\n",
      "  2.38206932e-01  6.41987678e-01  1.00609330e+00  2.33159552e-01\n",
      "  4.22778121e-01 -3.53092076e-01 -2.90744306e-01 -3.80716116e-01\n",
      " -9.62423327e-01 -4.49692076e-01  5.13214009e-01  2.19832864e-01\n",
      "  2.27002285e-01 -5.01169772e-02 -1.79082775e-02 -9.59642147e-01\n",
      "  1.67395334e-02 -3.27257717e-01 -1.39435386e-01  4.28358923e-01\n",
      " -8.46069990e-01  7.51083220e-01 -9.31135045e+00]\n"
     ]
    }
   ],
   "source": [
    "predict = logic3.predict(test_x)\n",
    "acc = sum(np.equal(predict, test_y)) / test_y.shape[0]\n",
    "print(f'test accuracy: {acc}')\n",
    "print(f'w: {logic3.w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926958831341302"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l2', max_iter=100)\n",
    "clf.fit(train_x, train_y)\n",
    "clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926958831341302"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.81505226e-03, -3.42208793e-06, -2.86806336e-03,\n",
       "         3.35205364e-04,  7.75880361e-04, -1.82173103e-02,\n",
       "         4.44679025e-04,  1.39450319e-04, -6.02054132e-03,\n",
       "         1.06410737e-03, -9.03960814e-05, -8.32870382e-05,\n",
       "        -1.81146254e-05, -7.09499410e-04, -1.05052212e-03,\n",
       "        -3.31609852e-04, -1.24935061e-04, -2.53074786e-04,\n",
       "        -4.94286894e-04, -3.98127449e-04, -9.97419202e-05,\n",
       "        -1.28378645e-04,  2.77673551e-03,  6.82903077e-04,\n",
       "        -4.66133137e-03,  1.75482048e-03, -5.15499570e-05,\n",
       "         8.29697695e-04, -2.30520166e-03, -3.16187453e-03,\n",
       "         2.18334910e-05,  1.04700807e-02, -3.02514577e-04,\n",
       "        -1.01326404e-02, -8.04850238e-04, -6.54136786e-04,\n",
       "        -2.33561267e-03, -8.27663339e-04,  3.20522029e-03,\n",
       "        -7.31337796e-04, -1.23209320e-03, -1.21118311e-03,\n",
       "        -3.31924428e-03, -1.63144337e-04,  2.46347924e-03,\n",
       "         1.98375023e-04, -2.67510070e-04,  1.11803231e-04,\n",
       "        -4.49302843e-04,  9.39796170e-03, -6.01084145e-03,\n",
       "        -8.94118547e-04, -5.36527343e-03, -2.89428545e-03,\n",
       "         1.20245481e-03, -2.72537097e-04, -9.19289816e-05,\n",
       "        -1.52420541e-03, -1.85284595e-04, -2.49014627e-03,\n",
       "        -7.34297126e-03,  2.77886891e-03,  7.21289733e-06,\n",
       "         2.03068305e-05,  2.16842409e-06, -5.15816821e-05,\n",
       "         2.43816985e-05, -6.78587695e-05, -1.51984162e-05,\n",
       "        -7.15472549e-05,  2.52734231e-05,  2.49986051e-05,\n",
       "         3.69161238e-05, -1.31079908e-05, -5.06233104e-05,\n",
       "        -2.67762651e-05, -8.08646795e-06,  8.51843439e-06,\n",
       "        -3.99747944e-06,  3.68304156e-05,  1.90255539e-05,\n",
       "        -9.79083288e-06,  2.91084382e-05, -4.24641274e-05,\n",
       "         2.55777285e-05, -8.68341003e-06, -3.99635328e-04,\n",
       "        -2.35553060e-05, -1.43847120e-05, -1.93400214e-05,\n",
       "         2.27844156e-05, -1.64225512e-05, -2.49824976e-05,\n",
       "        -7.25954345e-05, -2.74488008e-06, -3.29000829e-05,\n",
       "         3.38586958e-05, -3.70536577e-06, -1.35052636e-05,\n",
       "        -3.82498947e-03, -7.00981786e-05,  1.11245601e-05]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105,)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.linalg.inv(tmp.T.dot(tmp) + 1 * np.identity(tmp.shape[1])).dot(tmp.T).dot(test_y)\n",
    "\n",
    "yy = expit(w.T.dot(tmp.T))\n",
    "gradient = np.identity(tmp.shape[1]).dot(w) + tmp.T.dot(yy-test_y)\n",
    "gradient.shape\n",
    "r = np.diagflat(yy*(1-yy))\n",
    "h = np.identity(tmp.shape[1]) + tmp.T.dot(r).dot(tmp)\n",
    "new_w = w - np.linalg.inv(h).dot(gradient)\n",
    "new_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0665434373666685"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = np.clip(yy, 1e-12, 1.-1e-12)\n",
    "np.sum(w.T.dot(np.identity(tmp.shape[1])).dot(w))/2 - np.sum(test_y*np.log(yy) + (1-test_y)*np.log(1-yy)) / yy.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psy",
   "language": "python",
   "name": "psy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
