{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資管四 唐瑋廷 B05705043 HW3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取&分析data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30162.000000</td>\n",
       "      <td>3.016200e+04</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "      <td>30162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.437902</td>\n",
       "      <td>1.897938e+05</td>\n",
       "      <td>10.121312</td>\n",
       "      <td>1092.007858</td>\n",
       "      <td>88.372489</td>\n",
       "      <td>40.931238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.134665</td>\n",
       "      <td>1.056530e+05</td>\n",
       "      <td>2.549995</td>\n",
       "      <td>7406.346497</td>\n",
       "      <td>404.298370</td>\n",
       "      <td>11.979984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.376900e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.176272e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.784250e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>2.376285e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.484705e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  30162.000000  3.016200e+04   30162.000000  30162.000000  30162.000000   \n",
       "mean      38.437902  1.897938e+05      10.121312   1092.007858     88.372489   \n",
       "std       13.134665  1.056530e+05       2.549995   7406.346497    404.298370   \n",
       "min       17.000000  1.376900e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.176272e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.784250e+05      10.000000      0.000000      0.000000   \n",
       "75%       47.000000  2.376285e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    30162.000000  \n",
       "mean        40.931238  \n",
       "std         11.979984  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_list = ['workclass', 'occupation', 'native-country']\n",
    "train_data = pd.read_csv('adult.data', skipinitialspace=True)\n",
    "for c in remove_list:\n",
    "    train_data = train_data[~train_data[c].isin(['?'])]\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把 binary variable 轉成 one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 104)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = pd.DataFrame(pd.get_dummies(train_data.drop('label', axis=1)))\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "檢查 one-hot feature，剔除樣本數不到10的 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162, 102)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in train_x.columns[6:]: # first 6 columns are continuous varibles\n",
    "    if sum(train_x[c]) < 10:\n",
    "        train_x = train_x.drop(c, axis=1)\n",
    "features = train_x.columns # use of test data\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30162,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {'<=50K': 0, '>50K': 1, '<=50K.': 0, '>50K.': 1}\n",
    "train_y = train_data['label'].map(label_dict)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取 test data 並只保留 training data 有的 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15060.000000</td>\n",
       "      <td>1.506000e+04</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "      <td>15060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.768327</td>\n",
       "      <td>1.896164e+05</td>\n",
       "      <td>10.112749</td>\n",
       "      <td>1120.301594</td>\n",
       "      <td>89.041899</td>\n",
       "      <td>40.951594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.380676</td>\n",
       "      <td>1.056150e+05</td>\n",
       "      <td>2.558727</td>\n",
       "      <td>7703.181842</td>\n",
       "      <td>406.283245</td>\n",
       "      <td>12.062831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.349200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.166550e+05</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.779550e+05</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>2.385888e+05</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>1.490400e+06</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>3770.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
       "count  15060.000000  1.506000e+04   15060.000000  15060.000000  15060.000000   \n",
       "mean      38.768327  1.896164e+05      10.112749   1120.301594     89.041899   \n",
       "std       13.380676  1.056150e+05       2.558727   7703.181842    406.283245   \n",
       "min       17.000000  1.349200e+04       1.000000      0.000000      0.000000   \n",
       "25%       28.000000  1.166550e+05       9.000000      0.000000      0.000000   \n",
       "50%       37.000000  1.779550e+05      10.000000      0.000000      0.000000   \n",
       "75%       48.000000  2.385888e+05      13.000000      0.000000      0.000000   \n",
       "max       90.000000  1.490400e+06      16.000000  99999.000000   3770.000000   \n",
       "\n",
       "       hours-per-week  \n",
       "count    15060.000000  \n",
       "mean        40.951594  \n",
       "std         12.062831  \n",
       "min          1.000000  \n",
       "25%         40.000000  \n",
       "50%         40.000000  \n",
       "75%         45.000000  \n",
       "max         99.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('adult.test', skipinitialspace=True)\n",
    "for c in remove_list:\n",
    "    test_data = test_data[~test_data[c].isin(['?'])]\n",
    "test_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 103)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = pd.DataFrame(pd.get_dummies(test_data.drop('label', axis=1)))\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 102)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in test_x.columns[6:]: # first 6 columns are continuous varibles\n",
    "    if c not in features:\n",
    "        test_x = test_x.drop(c, axis=1)\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = test_data['label'].map(label_dict)\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()\n",
    "test_x = test_x.to_numpy()\n",
    "train_y = train_y.to_numpy()\n",
    "test_y = test_y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E(\\omega) = \\frac{1}{2}\\omega^T\\Lambda\\omega - \\sum_{i=1}^n\\{t_nln(y_n) + (1-t_n)ln(1-y_n)\\},\\,y_n = \\frac{1}{1+exp(-\\omega^Tx_n)}$$\\\n",
    "$$\\nabla E(\\omega) = \\frac{1}{2}(\\Lambda^T + \\Lambda)\\omega + \\sum_{i=1}^n (y_i - t_i)x_i = \\Lambda\\omega + x^T (y - t)$$\\\n",
    "$$H = \\nabla\\nabla E(\\omega) = \\Lambda + \\sum_{i=1}^n y_i(1-y_i)x_i x_i^T = \\Lambda + x R x^T$$\n",
    "<center>where R is a NxN diagonal matrix with elements: $R_{nn} = y_n(1-y_n)$<\\center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 1000, tol = 1e-5, add_intercept = True):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "       \n",
    "    def fit(self, x, t):\n",
    "        # add intercept\n",
    "        if self.add_intercept:\n",
    "            x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
    "    \n",
    "        # init w\n",
    "        b = self.reg_vec.trace() / self.reg_vec.shape[0]\n",
    "        self.w = np.linalg.inv(x.T.dot(x) + b * np.identity(x.shape[1])).dot(x.T).dot(t)\n",
    "        \n",
    "        last_err = float(\"-inf\")\n",
    "        for _ in range(self.max_iter):\n",
    "            # Newton-Raphson optimization method\n",
    "            y = expit(self.w.T.dot(x.T))\n",
    "            cur_err = self.err(y, t)\n",
    "#             print(cur_err, (self.w**2).sum())\n",
    "            if (cur_err - last_err) < self.tol:\n",
    "                break\n",
    "            last_err = cur_err\n",
    "            \n",
    "            gradient = self.reg_vec.dot(self.w) + x.T.dot(y-t)\n",
    "            r = np.diagflat(y*(1-y))\n",
    "            h = self.reg_vec + x.T.dot(r).dot(x)\n",
    "            \n",
    "            self.w = self.w - np.linalg.inv(h).dot(gradient)\n",
    "            \n",
    "            pred = np.where(y > 0.5, 1, 0)\n",
    "#             print(f'acc: {sum(np.equal(pred, t)) / t.shape[0]}')\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.add_intercept:\n",
    "            x = np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)\n",
    "        p = expit(self.w.T.dot(x.T))\n",
    "        return np.where(p > 0.5, 1, 0)\n",
    "    \n",
    "    def err(self, y, t):\n",
    "        y = np.clip(y, 1e-12, 1.-1e-12)\n",
    "        return np.sum(self.w.T.dot(self.reg_vec).dot(self.w))/2 - np.sum(t*np.log(y) + (1-t)*np.log(1-y)) / y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 1: lambda = 1 for all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic1 = mylogistic_l2(np.identity(train_x.shape[1]+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict & show test accuracy and learned w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8480743691899071\n",
      "w: [ 2.48591297e-02  7.26281835e-07  1.85806163e-01  3.16590245e-04\n",
      "  6.38679434e-04  2.90215841e-02  1.89694410e-01 -4.97719502e-01\n",
      " -3.10975203e-01 -1.29181492e-01 -7.94111558e-01 -6.18745004e-01\n",
      " -1.17270706e+00 -4.52249248e-01 -5.44907404e-01 -3.82721833e-01\n",
      " -9.99810311e-02 -2.62922226e-01 -6.29791390e-01 -4.96565840e-01\n",
      " -3.08326937e-01 -1.27584811e-01  1.28534378e-01  5.87953356e-01\n",
      " -2.50481307e-01  2.99991415e-01 -1.37579993e+00  6.82097030e-01\n",
      " -1.00989638e-01 -1.00975740e+00  1.19612260e+00  8.38966951e-01\n",
      " -9.56673074e-01 -1.50523219e+00 -1.08232392e+00 -8.14848370e-01\n",
      " -8.78492153e-02 -2.46913578e-02  7.15174653e-01 -1.06504054e+00\n",
      " -7.73348089e-01 -3.53722827e-01 -9.03671285e-01 -1.69395624e+00\n",
      "  4.29670534e-01  4.99488476e-01  2.05962312e-01  5.68478621e-01\n",
      " -1.78947443e-01 -5.76254831e-01 -3.75781230e-01 -1.12608336e+00\n",
      " -1.50192093e+00 -5.01524893e-01  7.47819833e-01 -1.02439618e+00\n",
      " -2.92668734e-01 -6.35195702e-01 -8.96890178e-01 -4.84594619e-01\n",
      " -2.09367501e+00 -1.24007040e+00  9.03420736e-01  4.04668560e-01\n",
      " -5.46920551e-01 -1.31374667e+00  4.27865169e-01 -9.47705967e-01\n",
      " -1.07395558e-01 -4.09492098e-01  3.77034140e-01  5.45751678e-01\n",
      "  5.23589384e-01 -6.70323916e-01 -1.09516216e-01  4.53277948e-02\n",
      " -1.63971889e-01 -4.71983492e-02 -4.02281404e-03 -3.44708812e-01\n",
      "  1.03362979e-01  4.50497096e-01  8.22875669e-01  9.41389496e-02\n",
      "  2.92357805e-01 -3.50891475e-01 -4.39859205e-01 -4.07586321e-01\n",
      " -6.90804284e-01 -4.47783816e-01  3.91129903e-01  8.03243758e-02\n",
      "  7.97357703e-02 -1.81402777e-01 -9.03628229e-02 -9.81576059e-01\n",
      " -7.79910252e-02 -3.31100773e-01 -1.88816101e-01  2.89337136e-01\n",
      " -8.34197419e-01  5.39068128e-01 -3.33374541e+00]\n"
     ]
    }
   ],
   "source": [
    "predict = logic1.predict(test_x)\n",
    "acc = sum(np.equal(predict, test_y)) / test_y.shape[0]\n",
    "print(f'test accuracy: {acc}')\n",
    "print(f'w: {logic1.w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 2: lambda = 1 for all but the intercept, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vec = np.identity(train_x.shape[1]+1)\n",
    "reg_vec[-1][-1] = 0\n",
    "logic2 = mylogistic_l2(reg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict & show test accuracy and learned w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.847808764940239\n",
      "w: [ 2.54336822e-02  7.50706804e-07  2.95324923e-01  3.17024478e-04\n",
      "  6.39652126e-04  2.94914512e-02  7.05717318e-01  1.78026500e-02\n",
      "  2.09126595e-01  3.82731145e-01 -2.79821711e-01 -1.04552949e-01\n",
      " -9.31003048e-01  9.08118762e-02 -1.06210390e-01 -5.68864880e-02\n",
      "  7.06129017e-01  5.36014978e-01  1.16361327e-01  1.37527872e-01\n",
      " -4.01951496e-01 -1.13370201e-01 -7.43801938e-02  6.79669927e-02\n",
      " -1.95742294e-02 -1.15929727e-02 -1.15969699e+00  2.67049827e-01\n",
      "  2.18010721e-02 -5.26538178e-01  1.61452758e+00  1.36751001e+00\n",
      " -4.92456781e-01 -1.01532722e+00 -6.05766415e-01 -3.41949002e-01\n",
      "  1.64109182e-01  2.28422252e-01  9.64856017e-01 -8.17967488e-01\n",
      " -5.20782272e-01 -9.91243550e-02 -6.49283758e-01 -1.55300394e+00\n",
      "  6.78427764e-01  7.51030497e-01  4.55411798e-01  8.18714335e-01\n",
      "  7.31938653e-02 -4.21151206e-02  1.99456866e-01 -5.83542666e-01\n",
      " -9.36996740e-01  7.53014758e-02  1.28789619e+00 -3.72048376e-01\n",
      "  3.94360616e-01  4.30693947e-02 -2.61235808e-01  1.95854174e-01\n",
      " -4.27150728e-01  4.27150728e-01  1.00965472e+00  5.02337197e-01\n",
      " -4.58396918e-01 -1.24053337e+00  5.27833699e-01 -8.67620758e-01\n",
      " -2.75702550e-02 -3.15345728e-01  4.72832596e-01  6.28755384e-01\n",
      "  6.23911101e-01 -5.88433188e-01 -2.96923355e-02  1.24844059e-01\n",
      " -1.43574430e-01  2.48070507e-02  6.14826819e-02 -2.48769643e-01\n",
      "  1.94794455e-01  5.25952046e-01  9.31972681e-01  1.87606692e-01\n",
      "  3.79606530e-01 -2.87259337e-01 -3.10421302e-01 -3.32413817e-01\n",
      " -6.50777756e-01 -3.81261235e-01  4.89030076e-01  1.76281854e-01\n",
      "  1.74545517e-01 -7.36414561e-02 -3.10934763e-02 -8.98503737e-01\n",
      "  6.72286129e-03 -2.72168679e-01 -1.23870297e-01  3.96789072e-01\n",
      " -7.54273373e-01  6.10526925e-01 -8.88722780e+00]\n"
     ]
    }
   ],
   "source": [
    "predict = logic2.predict(test_x)\n",
    "acc = sum(np.equal(predict, test_y)) / test_y.shape[0]\n",
    "print(f'test accuracy: {acc}')\n",
    "print(f'w: {logic2.w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vec = np.diagflat(np.array([1]*6 + [0.5]*(train_x.shape[1]-6) + [0]))\n",
    "logic3 = mylogistic_l2(reg_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logic3.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict & show test accuracy and learned w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.847675962815405\n",
      "w: [ 2.54757306e-02  7.51944312e-07  3.19092342e-01  3.17319913e-04\n",
      "  6.40115460e-04  2.95135991e-02  7.66990116e-01  7.62915465e-02\n",
      "  2.68338059e-01  4.43128005e-01 -2.20821080e-01 -4.63422172e-02\n",
      " -1.28758443e+00  2.18992475e-01 -2.26138731e-03  2.18816236e-02\n",
      "  9.74981437e-01  7.54034100e-01  2.92224730e-01  2.93070078e-01\n",
      " -4.19612080e-01 -1.04346489e-01 -1.12963414e-01 -3.78240642e-02\n",
      "  3.76517836e-02 -7.30516163e-02 -2.08394383e+00  1.86338344e-01\n",
      "  5.48283061e-02 -5.72016463e-01  1.82571096e+00  1.39641689e+00\n",
      " -5.47067026e-01 -1.05936562e+00 -6.55642151e-01 -3.88036591e-01\n",
      "  2.36234456e-01  3.00253533e-01  1.03825745e+00 -7.52669809e-01\n",
      " -4.53424415e-01 -2.69071693e-02 -5.82347571e-01 -2.00233647e+00\n",
      "  7.51037233e-01  8.27361969e-01  5.28330008e-01  8.95057963e-01\n",
      "  1.45241841e-01 -8.34438407e-02  2.32699144e-01 -5.92702337e-01\n",
      " -9.22764551e-01  1.11240624e-01  1.25497096e+00 -3.83664192e-01\n",
      "  4.13058381e-01  4.13741738e-02 -2.63868161e-01  1.93099799e-01\n",
      " -4.29102319e-01  4.29102319e-01  1.18913496e+00  5.50823608e-01\n",
      " -4.76703525e-01 -1.45906500e+00  5.82266265e-01 -1.06198153e+00\n",
      " -9.41603138e-03 -3.18451360e-01  5.24213674e-01  7.29262555e-01\n",
      "  6.74417681e-01 -6.38233985e-01 -9.70381962e-03  1.74242999e-01\n",
      " -2.36216831e-01  3.80746796e-02  1.00364760e-01 -2.47188688e-01\n",
      "  2.38206932e-01  6.41987678e-01  1.00609330e+00  2.33159552e-01\n",
      "  4.22778121e-01 -3.53092076e-01 -2.90744306e-01 -3.80716116e-01\n",
      " -9.62423327e-01 -4.49692076e-01  5.13214009e-01  2.19832864e-01\n",
      "  2.27002285e-01 -5.01169772e-02 -1.79082775e-02 -9.59642147e-01\n",
      "  1.67395334e-02 -3.27257717e-01 -1.39435386e-01  4.28358923e-01\n",
      " -8.46069990e-01  7.51083220e-01 -9.31135045e+00]\n"
     ]
    }
   ],
   "source": [
    "predict = logic3.predict(test_x)\n",
    "acc = sum(np.equal(predict, test_y)) / test_y.shape[0]\n",
    "print(f'test accuracy: {acc}')\n",
    "print(f'w: {logic3.w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split the training data into subtraining and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27145, 102) (27145,) (3017, 102) (3017,)\n"
     ]
    }
   ],
   "source": [
    "m = train_x.shape[0]*9//10\n",
    "subtrain_x, subtrain_y = train_x[:m], train_y[:m]\n",
    "tune_x, tune_y = train_x[m:], train_y[m:]\n",
    "print(subtrain_x.shape, subtrain_y.shape, tune_x.shape, tune_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "決定 regularization coefficient list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_coef_list = [0.01, 0.02, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1: constraint that $a_1 = a_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1: 0.01, a2: 0.01, test accuracy: 0.8336095459065297\n",
      "a1: 0.02, a2: 0.02, test accuracy: 0.8336095459065297\n",
      "a1: 0.05, a2: 0.05, test accuracy: 0.8336095459065297\n",
      "a1: 0.1, a2: 0.1, test accuracy: 0.843221743453762\n",
      "a1: 0.5, a2: 0.5, test accuracy: 0.8428902883659264\n",
      "a1: 1, a2: 1, test accuracy: 0.8428902883659264\n",
      "a1: 5, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 10, a2: 10, test accuracy: 0.8422273781902552\n",
      "a1: 50, a2: 50, test accuracy: 0.8405701027510772\n",
      "a1: 100, a2: 100, test accuracy: 0.839907192575406\n"
     ]
    }
   ],
   "source": [
    "tune_acc = []\n",
    "for a in reg_coef_list:\n",
    "    reg_vec = np.diagflat(np.array([a]*6 + [a]*(train_x.shape[1]-6) + [0]))\n",
    "    logic = mylogistic_l2(reg_vec)\n",
    "    logic.fit(subtrain_x, subtrain_y)\n",
    "    predict = logic.predict(tune_x)\n",
    "    acc = sum(np.equal(predict, tune_y)) / tune_y.shape[0]\n",
    "    tune_acc.append(acc)\n",
    "    print(f'a1: {a}, a2: {a}, test accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2: fix $a_1 = a_1^*$ and search $a_2$. In this case, $a_1 = 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1: 5, a2: 0.01, test accuracy: 0.8336095459065297\n",
      "a1: 5, a2: 0.02, test accuracy: 0.8336095459065297\n",
      "a1: 5, a2: 0.05, test accuracy: 0.8336095459065297\n",
      "a1: 5, a2: 0.1, test accuracy: 0.843221743453762\n",
      "a1: 5, a2: 0.5, test accuracy: 0.8428902883659264\n",
      "a1: 5, a2: 1, test accuracy: 0.843221743453762\n",
      "a1: 5, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 5, a2: 10, test accuracy: 0.8422273781902552\n",
      "a1: 5, a2: 50, test accuracy: 0.8405701027510772\n",
      "a1: 5, a2: 100, test accuracy: 0.839907192575406\n"
     ]
    }
   ],
   "source": [
    "tune_acc = []\n",
    "for a in reg_coef_list:\n",
    "    reg_vec = np.diagflat(np.array([5]*6 + [a]*(train_x.shape[1]-6) + [0]))\n",
    "    logic = mylogistic_l2(reg_vec)\n",
    "    logic.fit(subtrain_x, subtrain_y)\n",
    "    predict = logic.predict(tune_x)\n",
    "    acc = sum(np.equal(predict, tune_y)) / tune_y.shape[0]\n",
    "    tune_acc.append(acc)\n",
    "    print(f'a1: {5}, a2: {a}, test accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3: fix $a_2 = a_2^*$ and search $a_1$. In this case, $a_2 = 5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1: 0.01, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 0.02, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 0.05, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 0.1, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 0.5, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 1, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 5, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 10, a2: 5, test accuracy: 0.8435531985415976\n",
      "a1: 50, a2: 5, test accuracy: 0.8438846536294332\n",
      "a1: 100, a2: 5, test accuracy: 0.8438846536294332\n"
     ]
    }
   ],
   "source": [
    "tune_acc = []\n",
    "for a in reg_coef_list:\n",
    "    reg_vec = np.diagflat(np.array([a]*6 + [5]*(train_x.shape[1]-6) + [0]))\n",
    "    logic = mylogistic_l2(reg_vec)\n",
    "    logic.fit(subtrain_x, subtrain_y)\n",
    "    predict = logic.predict(tune_x)\n",
    "    acc = sum(np.equal(predict, tune_y)) / tune_y.shape[0]\n",
    "    tune_acc.append(acc)\n",
    "    print(f'a1: {a}, a2: {5}, test accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best hyper-parameters: $a_1 = 50, a_2 = 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 4: using $a_1 = 50, a_2 = 5$, train the model on training data, and test on test date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1: 50, a2: 5, test accuracy: 0.84867197875166\n"
     ]
    }
   ],
   "source": [
    "reg_vec = np.diagflat(np.array([50]*6 + [5]*(train_x.shape[1]-6) + [0]))\n",
    "logic = mylogistic_l2(reg_vec)\n",
    "logic.fit(train_x, train_y)\n",
    "predict = logic.predict(test_x)\n",
    "acc = sum(np.equal(predict, test_y)) / test_y.shape[0]\n",
    "print(f'a1: {50}, a2: {5}, test accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use l2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926958831341302"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty='l2', max_iter=100)\n",
    "clf.fit(train_x, train_y)\n",
    "clf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.81505185e-03, -3.42208798e-06, -2.86806326e-03,\n",
       "         3.35205365e-04,  7.75880389e-04, -1.82173095e-02,\n",
       "         4.44679003e-04,  1.39450311e-04, -6.02054102e-03,\n",
       "         1.06410731e-03, -9.03960774e-05, -8.32870342e-05,\n",
       "        -1.81146245e-05, -7.09499374e-04, -1.05052206e-03,\n",
       "        -3.31609835e-04, -1.24935055e-04, -2.53074773e-04,\n",
       "        -4.94286869e-04, -3.98127428e-04, -9.97419152e-05,\n",
       "        -1.28378639e-04,  2.77673537e-03,  6.82903042e-04,\n",
       "        -4.66133113e-03,  1.75482039e-03, -5.15499544e-05,\n",
       "         8.29697652e-04, -2.30520154e-03, -3.16187437e-03,\n",
       "         2.18334899e-05,  1.04700801e-02, -3.02514562e-04,\n",
       "        -1.01326399e-02, -8.04850197e-04, -6.54136753e-04,\n",
       "        -2.33561255e-03, -8.27663298e-04,  3.20522013e-03,\n",
       "        -7.31337759e-04, -1.23209314e-03, -1.21118305e-03,\n",
       "        -3.31924411e-03, -1.63144328e-04,  2.46347911e-03,\n",
       "         1.98375013e-04, -2.67510057e-04,  1.11803225e-04,\n",
       "        -4.49302820e-04,  9.39796122e-03, -6.01084114e-03,\n",
       "        -8.94118502e-04, -5.36527315e-03, -2.89428531e-03,\n",
       "         1.20245475e-03, -2.72537083e-04, -9.19289771e-05,\n",
       "        -1.52420533e-03, -1.85284585e-04, -2.49014615e-03,\n",
       "        -7.34297089e-03,  2.77886876e-03,  7.21289696e-06,\n",
       "         2.03068295e-05,  2.16842397e-06, -5.15816794e-05,\n",
       "         2.43816973e-05, -6.78587660e-05, -1.51984154e-05,\n",
       "        -7.15472512e-05,  2.52734218e-05,  2.49986038e-05,\n",
       "         3.69161219e-05, -1.31079901e-05, -5.06233078e-05,\n",
       "        -2.67762638e-05, -8.08646753e-06,  8.51843395e-06,\n",
       "        -3.99747924e-06,  3.68304137e-05,  1.90255529e-05,\n",
       "        -9.79083239e-06,  2.91084367e-05, -4.24641253e-05,\n",
       "         2.55777272e-05, -8.68340958e-06, -3.99635308e-04,\n",
       "        -2.35553048e-05, -1.43847113e-05, -1.93400204e-05,\n",
       "         2.27844144e-05, -1.64225504e-05, -2.49824964e-05,\n",
       "        -7.25954308e-05, -2.74487994e-06, -3.29000813e-05,\n",
       "         3.38586940e-05, -3.70536558e-06, -1.35052629e-05,\n",
       "        -3.82498928e-03, -7.00981750e-05,  1.11245595e-05]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use newton-cg solver without penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/white123/miniconda3/envs/sl/lib/python3.7/site-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/white123/miniconda3/envs/sl/lib/python3.7/site-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/home/white123/miniconda3/envs/sl/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.84800796812749"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='newton-cg', penalty='none', max_iter=100)\n",
    "clf.fit(train_x, train_y)\n",
    "clf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.47065554e-02,  7.34148985e-07,  1.62619328e-01,\n",
       "         3.16595827e-04,  6.37016209e-04,  2.91658465e-02,\n",
       "         1.08429642e-01, -5.88940930e-01, -3.99253426e-01,\n",
       "        -2.15826650e-01, -8.89052154e-01, -7.12318705e-01,\n",
       "        -3.47660518e-01, -6.03779261e-01, -6.82602162e-01,\n",
       "        -4.32500457e-01, -2.27046955e-01, -4.20675412e-01,\n",
       "        -7.97224501e-01, -6.28216289e-01, -3.01625710e-01,\n",
       "        -1.46350517e-01,  1.63240437e-01,  6.93479250e-01,\n",
       "        -3.14462237e-01,  3.55903914e-01, -3.41096963e-01,\n",
       "         7.77288976e-01, -1.38954853e-01, -8.04515514e-01,\n",
       "         5.15616154e-01,  7.05637452e-01, -6.68669811e-01,\n",
       "        -1.32375347e+00, -8.67855788e-01, -6.01081765e-01,\n",
       "        -1.88273262e-01, -1.25735296e-01,  6.14336599e-01,\n",
       "        -1.17981430e+00, -8.98437831e-01, -4.67590648e-01,\n",
       "        -1.01065898e+00, -6.85523186e-01,  3.25306062e-01,\n",
       "         4.00761869e-01,  1.03015352e-01,  4.64524132e-01,\n",
       "        -2.86411220e-01, -3.47757651e-01, -4.77471282e-01,\n",
       "        -9.96036794e-01, -1.56637719e+00, -6.32569903e-01,\n",
       "         9.75590083e-01, -8.33331322e-01, -3.90632767e-01,\n",
       "        -6.21343738e-01, -7.42497841e-01, -4.56817072e-01,\n",
       "        -1.94826687e+00, -1.09635587e+00,  3.32002624e-01,\n",
       "         2.26083507e-01, -3.97896917e-01, -6.37820995e-01,\n",
       "         2.19339091e-01, -4.53468077e-01, -1.00337067e-01,\n",
       "        -3.38013747e-01,  1.90807170e-01,  2.11485548e-01,\n",
       "         3.26248944e-01, -3.88071151e-01, -1.17349004e-01,\n",
       "        -4.68819085e-02, -3.70642447e-02, -2.77384246e-02,\n",
       "        -4.01706907e-02, -2.99652063e-01, -1.48123905e-02,\n",
       "         1.24229617e-01,  5.00635838e-01, -4.12171785e-02,\n",
       "         1.56509369e-01, -1.19938264e-01, -5.89066152e-01,\n",
       "        -2.11486007e-01, -1.80516476e-01, -1.94200612e-01,\n",
       "         3.04045173e-01, -5.04318709e-02, -4.61292524e-02,\n",
       "        -2.52326097e-01, -5.33765706e-02, -6.36784094e-01,\n",
       "        -5.44859080e-02, -1.14714832e-01, -8.90588455e-02,\n",
       "         1.95816890e-01, -4.46411667e-01,  1.52283760e-01]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use newton-cg solver with l2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/white123/miniconda3/envs/sl/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.848339973439575"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='newton-cg', penalty='l2', max_iter=100)\n",
    "clf.fit(train_x, train_y)\n",
    "clf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.43657625e-02,  7.20183272e-07,  1.60023435e-01,\n",
       "         3.16116321e-04,  6.35570289e-04,  2.88959454e-02,\n",
       "         9.86956246e-02, -5.90820587e-01, -4.10594945e-01,\n",
       "        -2.24584981e-01, -8.92813698e-01, -7.15945527e-01,\n",
       "        -1.60465091e-01, -6.10246854e-01, -6.86085506e-01,\n",
       "        -4.31352771e-01, -2.11157150e-01, -4.04312797e-01,\n",
       "        -8.21057486e-01, -6.30510743e-01, -2.94716918e-01,\n",
       "        -1.46271252e-01,  1.67091701e-01,  6.92588756e-01,\n",
       "        -3.21562750e-01,  3.59841075e-01, -1.82717670e-01,\n",
       "         7.67706395e-01, -1.43765237e-01, -7.19946582e-01,\n",
       "         2.58231986e-01,  6.34303234e-01, -5.53309742e-01,\n",
       "        -1.23582845e+00, -7.70972788e-01, -5.09006863e-01,\n",
       "        -2.08694982e-01, -1.48175826e-01,  5.91397339e-01,\n",
       "        -1.17724037e+00, -9.00896572e-01, -4.85917464e-01,\n",
       "        -1.02643418e+00, -3.81112460e-01,  3.06492019e-01,\n",
       "         3.72676668e-01,  8.11478509e-02,  4.41098904e-01,\n",
       "        -3.06197850e-01, -2.33538140e-01, -5.20618274e-01,\n",
       "        -9.69661101e-01, -1.58316423e+00, -6.66857952e-01,\n",
       "         1.07731049e+00, -7.92040103e-01, -4.22779901e-01,\n",
       "        -5.87921832e-01, -6.72489682e-01, -4.21297687e-01,\n",
       "        -1.87388403e+00, -1.02264518e+00,  1.46295283e-01,\n",
       "         9.99365360e-02, -2.70202922e-01, -3.71556911e-01,\n",
       "         8.01959338e-02, -2.84483317e-01, -7.95663770e-02,\n",
       "        -2.40856983e-01,  7.69245158e-02,  9.27490401e-02,\n",
       "         1.78526601e-01, -2.25981066e-01, -9.39333927e-02,\n",
       "        -4.89552612e-02, -2.00957625e-02, -2.26719635e-02,\n",
       "        -3.08754170e-02, -2.54527529e-01, -4.37023492e-02,\n",
       "         4.34487444e-02,  2.56448190e-01, -6.90043816e-02,\n",
       "         6.70273029e-02, -6.40545954e-02, -6.87425469e-01,\n",
       "        -1.30305708e-01, -9.16909683e-02, -1.08923012e-01,\n",
       "         2.46057294e-01, -8.15805741e-02, -5.88208894e-02,\n",
       "        -2.45348326e-01, -3.15702782e-02, -3.90122206e-01,\n",
       "        -4.20264200e-02, -5.90340996e-02, -5.45582350e-02,\n",
       "         1.30730648e-01, -2.68083801e-01,  5.82111627e-02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best test acc of my own model: 0.84867197875166\n",
    "### best test acc of sklearn model: 0.848339973439575"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著比較 w 參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "my own model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of w^2 = 85.22593630608262\n"
     ]
    }
   ],
   "source": [
    "print(f'sum of w^2 = {(logic.w**2).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of w^2 = 27.254167924206236\n"
     ]
    }
   ],
   "source": [
    "print(f'sum of w^2 = {(clf.coef_**2).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結論：在 best test accuracy 上，兩者的結果差異不大，但 sklearn model 的 solver 和 penalty 選擇會蠻大程度影響到結果的，而 IRLS 在結果上相對穩定，幾乎都有達到 83% 以上。可能的原因是 IRLS 直接用 closed-form solution 求解，再用牛頓法更新參數，相對較為穩定，但運行的速度也較慢。而 w 的 square sum 則是 sklearn model 較小，自己的 model 較大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
